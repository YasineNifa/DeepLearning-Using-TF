{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_in_tensorflow_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0QJVeowPEQrEMZIIWHk4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasineNifa/DeepLearning-Using-TF/blob/master/nlp_in_tensorflow_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtoaAjuDEELA"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a Recurrent Neural Network (RNN).\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog.\n",
        "\n",
        "See what happened there?\n",
        "\n",
        "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
        "\n",
        "For a simple example, take two sentences:\n",
        "\n",
        "* Massive earthquake last week, no?\n",
        "* No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "\n",
        "* One to one: one input, one output, such as image classification.\n",
        "* One to many: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* Many to one: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* Many to many: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "\n",
        "* Long short-term memory cells (LSTMs).\n",
        "* Gated recurrent units (GRUs).\n",
        "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences.\n",
        "\n",
        "For a deeper understanding of what's happening behind the scenes of the code we're about to write, I'd recommend the following resources:\n",
        "\n",
        "> üìñ Resources:\n",
        "* MIT Deep Learning Lecture on Recurrent Neural Networks - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "* The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "* Understanding LSTMs by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoq1aXOSE8Dm"
      },
      "source": [
        "### Model 2 : LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaalyanLD-5H",
        "outputId": "86648bc3-fcda-4553-ca34-6ed3d8f05171"
      },
      "source": [
        "# Download data \n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-15 13:23:25--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 173.194.76.128, 66.102.1.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-04-15 13:23:25 (67.0 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNVDI92-EJaZ"
      },
      "source": [
        "import zipfile\n",
        "def unzip_data(filename):\n",
        "  zip_ref = zipfile.ZipFile(filename)\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwF8AAG7GFc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wgM389dFf7O"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "AY7ucuKmFzO6",
        "outputId": "84641fbc-985d-4202-ef6e-24de721b639c"
      },
      "source": [
        "train_df_shuffled = train_df.sample(frac=1,random_state=42)\n",
        "train_df_shuffled.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dvERhFXGI_i"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                  train_df_shuffled['target'].to_numpy(),\n",
        "                                                                  test_size = 0.1,\n",
        "                                                                  random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POf_sV17HEEA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode = \"int\",\n",
        "                                    output_sequence_length=max_length)\n",
        "\n",
        "text_vectorizer.adapt(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wG6v0ZITkn"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                             output_dim = 128,# size of embedding vector\n",
        "                             embeddings_initializer = \"uniform\",\n",
        "                             input_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1z6VSQLHYW-"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name = \"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_D_mLQOJkgC"
      },
      "source": [
        "> üîë Note: Reading the documentation for the TensorFlow LSTM layer, you'll find a plethora of parameters. Many of these have been tuned to make sure they compute as fast as possible. The main ones you'll be looking to adjust are units (number of hidden units) and return_sequences (set this to True when stacking LSTM or other recurrent layers).\n",
        "\n",
        "Now we've got our LSTM model built, let's compile it using \"binary_crossentropy\" loss and the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhprKQYjJYTc"
      },
      "source": [
        "model_2.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqWJPxWyJ2OJ",
        "outputId": "543f7d6e-86ab-443d-e2f1-0b36a4ec7eb9"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdUjgwcKxtQ"
      },
      "source": [
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVBLdAzXJ3sO",
        "outputId": "d4d99c7e-c8da-4932-bd48-3e56938a2d98"
      },
      "source": [
        "SAVE_DIR = \"model_logs\"\n",
        "model_2.fit(train_data,train_labels,epochs=5,\n",
        "            validation_data = (val_data,val_labels),\n",
        "            callbacks = [create_tensorboard_callback(SAVE_DIR,\"LSTM\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20210415-132334\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 36s 26ms/step - loss: 0.5785 - accuracy: 0.6821 - val_loss: 0.4551 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3061 - accuracy: 0.8780 - val_loss: 0.4668 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.2085 - accuracy: 0.9262 - val_loss: 0.5118 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.1483 - accuracy: 0.9489 - val_loss: 0.6295 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 0.7537 - val_accuracy: 0.7677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95c0322150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIsyR4HVLE1y",
        "outputId": "843033a3-19f2-4ca5-cd26-a49d39c5e904"
      },
      "source": [
        "model_2_pred_probs = model_2.predict(val_data)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03278309],\n",
              "       [0.7701728 ],\n",
              "       [0.9975758 ],\n",
              "       [0.03116872],\n",
              "       [0.00884641],\n",
              "       [0.9987531 ],\n",
              "       [0.93596745],\n",
              "       [0.99893993],\n",
              "       [0.99885297],\n",
              "       [0.08126581]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U4f9f53LecJ",
        "outputId": "0b1f716b-ab29-4e8b-99cb-b38f89e579ba"
      },
      "source": [
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lr-Ai-0L8SW"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra2UbzNVLrpp",
        "outputId": "f18d8942-b2b7-416c-9c18-e6cc03ba55e2"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7656749923220023,\n",
              " 'precision': 0.7691343474319641,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SQvnvNaMFjr"
      },
      "source": [
        "## Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "> for better explanation : \n",
        "* Gated Recurrent Unit Wikipedia page\n",
        "* Understanding GRU networks by Simeon Kostadinov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4nPli-KMAzb"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x) #return_sequences=True comme LSTM()\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs=input, outputs= outputs, name =\"model_3_GRU\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z0DjD86Vg0c"
      },
      "source": [
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ztUtE8sVgsJ",
        "outputId": "c4997f4d-9001-4e51-e7f4-6241145264fa"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwb0MsfDV-1c"
      },
      "source": [
        "\n",
        "Notice the difference in number of trainable parameters between model_2 (LSTM) and model_3 (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHlc2C8CVgog",
        "outputId": "d80a859b-83e7-47a8-ba12-ccf050b6c926"
      },
      "source": [
        "model_3_history = model_3.fit(train_data,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_data,val_labels),\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR,\"GRU\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210415-132430\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 26ms/step - loss: 0.3416 - accuracy: 0.8408 - val_loss: 0.7335 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0939 - accuracy: 0.9666 - val_loss: 0.7621 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.0746 - accuracy: 0.9711 - val_loss: 0.7909 - val_accuracy: 0.7598\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0644 - accuracy: 0.9765 - val_loss: 1.0122 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0517 - accuracy: 0.9781 - val_loss: 0.9902 - val_accuracy: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYh-KAfqWj4s"
      },
      "source": [
        "Time to make some predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzQ5mSoDWdCd",
        "outputId": "98793eaa-83b1-452d-b942-ca5efe913a97"
      },
      "source": [
        "model_3_preds_probs = model_3.predict(val_data)\n",
        "model_3_preds_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.2643820e-03],\n",
              "       [6.3674587e-01],\n",
              "       [9.9985552e-01],\n",
              "       [1.0645943e-01],\n",
              "       [6.3347851e-04],\n",
              "       [9.9981278e-01],\n",
              "       [9.8658806e-01],\n",
              "       [9.9988687e-01],\n",
              "       [9.9978119e-01],\n",
              "       [1.4961442e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdvixvrEW26Y"
      },
      "source": [
        "Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9tMl0RiWwpN",
        "outputId": "418c3f66-a728-474d-c4a0-3341590427b6"
      },
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_preds_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrf1qy1FXlEi"
      },
      "source": [
        "Now we've got predicted classes, let's evaluate them against the ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_2mCH12XBJj",
        "outputId": "1e4820d9-3c8e-4219-946b-810ee2fc370c"
      },
      "source": [
        "model_3_results = calculate_results(y_true=val_labels, y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.37795275590551,\n",
              " 'f1': 0.7621412379223811,\n",
              " 'precision': 0.764383846466808,\n",
              " 'recall': 0.7637795275590551}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM7HTO4tX1LG"
      },
      "source": [
        "Finally we can compare our GRU model's results to our baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDNYnmWIXxYi"
      },
      "source": [
        "\n",
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "#compare_baseline_to_new_results(baseline_results=baseline_results, new_model_results=model_1_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1k_lcNMYLuF",
        "outputId": "da2783bd-2b40-4316-c213-e350896d09aa"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab),words_in_vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gFfirydYnVQ"
      },
      "source": [
        "And now let's get our embedding layer's weights (these are the numerical representations of each word).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcSEzLxJYjL7",
        "outputId": "93b312c9-e710-481b-b56c-d1b16b23ab91"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_data, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_data, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210415-132458\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.6244 - accuracy: 0.7378 - val_loss: 0.5314 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.4080 - accuracy: 0.8716 - val_loss: 0.4675 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.2934 - accuracy: 0.9023 - val_loss: 0.4608 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.2291 - accuracy: 0.9282 - val_loss: 0.4718 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1920 - accuracy: 0.9386 - val_loss: 0.4936 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic0-igxuYrkt",
        "outputId": "351c1355-d2b6-41f9-d8c3-7eaa1371e3bf"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_data, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZxAmttZZccN",
        "outputId": "c0cb5443-345d-45e4-9fcf-454931d99fd6"
      },
      "source": [
        "baseline_score = model_0.score(val_data, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AApZbr4KZwpO",
        "outputId": "15441766-da3d-4fc3-c7b9-dd14096e4f08"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_data)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYCCpCsIZoyV",
        "outputId": "32ab7eda-b59d-4d91-c1e1-7ddd812fa252"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zStW0T5JZtCg",
        "outputId": "0c9c2a02-78ea-4ac5-fd6c-f5fa5dfe0e54"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoslIJzpZ9_5",
        "outputId": "0610e403-1b2f-406f-eef2-97d4d374113b"
      },
      "source": [
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1tVWCfyacgs"
      },
      "source": [
        "### Model 4: Bidirectonal RNN model\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM6yO5r9aNjr"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(input,outputs,name=\"model_4_Bidirectional\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLcnHHiybaup"
      },
      "source": [
        "> üîë Note: You can use the Bidirectional wrapper on any RNN cell in TensorFlow. For example, layers.Bidirectional(layers.GRU(64)) creates a bidirectional GRU cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SolLXCYGbXOW",
        "outputId": "070be1b0-cafd-4afa-f1dc-60fc7fbde324"
      },
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5JWujI3bwWv"
      },
      "source": [
        "Notice the increased number of trainable parameters in model_4 (bidirectional LSTM) compared to model_2 (regular LSTM). This is due to the bidirectionality we added to our RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGaGy2j_brgc",
        "outputId": "8ab8ba99-7819-472e-d881-c7ab06aaeef9"
      },
      "source": [
        "model_4_history =model_4.fit(train_data,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_data,val_labels),\n",
        "            callbacks = [create_tensorboard_callback(SAVE_DIR,\"bidirectional_RNN\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20210415-132520\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 34ms/step - loss: 0.2191 - accuracy: 0.9289 - val_loss: 0.8347 - val_accuracy: 0.7782\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0792 - accuracy: 0.9697 - val_loss: 0.9824 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.0571 - accuracy: 0.9744 - val_loss: 1.1421 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0417 - accuracy: 0.9805 - val_loss: 1.2000 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0433 - accuracy: 0.9821 - val_loss: 1.1701 - val_accuracy: 0.7664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmnj8wQncHDw",
        "outputId": "46ffb02e-1919-4020-d85d-7d3025356747"
      },
      "source": [
        "model_4_pred_probs = model_4.predict(val_data)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.7252911e-03],\n",
              "       [7.9630148e-01],\n",
              "       [9.9989784e-01],\n",
              "       [7.6241687e-02],\n",
              "       [2.0245909e-04],\n",
              "       [9.9979705e-01],\n",
              "       [9.9869859e-01],\n",
              "       [9.9993610e-01],\n",
              "       [9.9986064e-01],\n",
              "       [1.8171802e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsgosjsAcQ24",
        "outputId": "b49481e2-1ae0-4663-ee3d-5f16e55f750d"
      },
      "source": [
        "model_4_pred = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_pred[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvl81IbWchGP",
        "outputId": "69bf4783-a1be-4d1f-f4e5-d2f26251f026"
      },
      "source": [
        "model_4_results = calculate_results(val_labels, model_4_pred)\n",
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'f1': 0.7651213533864446,\n",
              " 'precision': 0.7665895370389821,\n",
              " 'recall': 0.7664041994750657}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSZ9ciZ-ctrZ",
        "outputId": "0bccb267-9f4f-428c-ad7b-a2af40ff0ea0"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results, model_4_results)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCiK4LnDc9a7"
      },
      "source": [
        "### Convolutional Neural Networks for Text\n",
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "> tensorflow.keras.layers.Conv1D() layer followed by a tensorflow.\n",
        "\n",
        "> keras.layers.GlobablMaxPool1D() layer.\n",
        "\n",
        "> üìñ Resource: The intuition here is explained succinctly in the paper Understanding Convolutional Neural Networks for Text Classification, where they state that CNNs classify text through the following steps:\n",
        "* 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "* 2-Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "* 3-The rest of the network classifies the text based on this information.\n",
        "\n",
        "###Model 5: Conv1D\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYI2I1Hac5md",
        "outputId": "38dc81e3-c11b-405d-de15-a0b8aa96627f"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(kernel_size=5,filters=32,activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(input,outputs,name=\"model_5_Conv1D\")\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_5.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAJ_ssp8iNIP",
        "outputId": "3df64129-f02d-4e21-f183-52891b0bd239"
      },
      "source": [
        "model_5.fit(train_data,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_data,val_labels),\n",
        "            callbacks = [create_tensorboard_callback(SAVE_DIR,\"Conv1D\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210415-132553\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 21ms/step - loss: 0.2149 - accuracy: 0.9357 - val_loss: 0.7628 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0815 - accuracy: 0.9701 - val_loss: 0.8899 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0672 - accuracy: 0.9748 - val_loss: 0.9843 - val_accuracy: 0.7546\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.0496 - accuracy: 0.9823 - val_loss: 1.0680 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0438 - accuracy: 0.9812 - val_loss: 1.1016 - val_accuracy: 0.7625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f951a7ae6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEb0bd5aikGM",
        "outputId": "e6274b29-4a9c-4cca-9f13-2751e2a48d2a"
      },
      "source": [
        "model_5_pred_probs = model_5.predict(val_data)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4801797e-01],\n",
              "       [8.8093263e-01],\n",
              "       [9.9982578e-01],\n",
              "       [4.1849084e-02],\n",
              "       [1.4853042e-06],\n",
              "       [9.9455124e-01],\n",
              "       [9.5227301e-01],\n",
              "       [9.9982268e-01],\n",
              "       [9.9999487e-01],\n",
              "       [6.0398501e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgzhBvMUitSv",
        "outputId": "7c945a7f-6fd7-435f-e4a0-98f1b6ebfff9"
      },
      "source": [
        "model_5_pred = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_pred[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS5O6UGIi0nc",
        "outputId": "132737d0-6744-4007-9bcb-9f804fa6825c"
      },
      "source": [
        "model_5_results = calculate_results(val_labels,model_5_pred)\n",
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'f1': 0.7613223680610013,\n",
              " 'precision': 0.762420601385426,\n",
              " 'recall': 0.7624671916010499}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_q__2eEi_wX",
        "outputId": "754b9f50-e08d-4bbc-d63c-ce9177a0608a"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.25, Difference: -3.02\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fBOJr8SjFYN"
      },
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP)\n",
        " a common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "\n",
        " For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        " More specifically, we're going to be using the Universal Sentence Encoder from TensorFlow Hub (a great resource containing a plethora of pretrained model resources for a variety of tasks)\n",
        "\n",
        " > üîë Note: There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case.\n",
        "\n",
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        ">üîë Note: An encoder is the name for a model which converts raw data such as text into a numerical representation (feature vector), a decoder converts the numerical representation to a desired output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYbA7m86jB0s"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")# load Universal Sentence Encoder\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOeebgV1k7k2",
        "outputId": "82ef8c60-d684-40eb-c885-daa0cea5ebf0"
      },
      "source": [
        "embed_samples = embed([\"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "embed_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[ 3.59669067e-02, -8.57946947e-02, -1.15274256e-02,\n",
              "         5.25985099e-03, -1.85217224e-02, -5.04201241e-02,\n",
              "        -3.61694023e-02,  5.34677971e-03,  4.80591543e-02,\n",
              "         4.69074100e-02, -3.72332968e-02, -1.14954282e-02,\n",
              "         4.35241386e-02,  7.05099404e-02,  7.09376112e-02,\n",
              "        -8.18042979e-02,  8.71717278e-03, -4.65412140e-02,\n",
              "        -2.24577747e-02,  4.68687378e-02,  2.02256767e-03,\n",
              "         3.09906770e-02,  2.04356033e-02,  6.39216900e-02,\n",
              "        -7.64108673e-02,  8.42118040e-02, -4.57603857e-02,\n",
              "        -1.06166315e-03, -2.05941461e-02,  1.24110701e-02,\n",
              "         5.72753996e-02,  3.81562077e-02, -2.74211671e-02,\n",
              "        -3.54349939e-03, -9.83258486e-02, -1.24485819e-02,\n",
              "         3.86562794e-02,  5.03195561e-02, -2.36250665e-02,\n",
              "         3.21847177e-03,  3.22520956e-02,  7.38093210e-03,\n",
              "         4.47310172e-02, -4.12236759e-03,  1.15160560e-02,\n",
              "         2.83772852e-02,  6.01372391e-04, -5.90335354e-02,\n",
              "        -4.94344393e-03, -6.88527944e-03, -4.12424020e-02,\n",
              "        -2.07703072e-03, -1.77202132e-02, -2.27782298e-02,\n",
              "        -2.42898185e-02,  1.39938109e-02, -5.17674983e-02,\n",
              "         5.97374998e-02,  3.81307527e-02, -3.59316617e-02,\n",
              "         3.09860837e-02,  6.09486829e-03, -4.37486954e-02,\n",
              "        -5.38942739e-02, -4.32431810e-02, -3.92870642e-02,\n",
              "         5.61528616e-02,  3.82246706e-03,  6.57870481e-03,\n",
              "        -4.53821979e-02,  3.96313444e-02, -5.69343567e-03,\n",
              "        -2.00726017e-02,  8.17294121e-02,  4.15083840e-02,\n",
              "         3.72894853e-02, -6.70029223e-02, -5.10405116e-02,\n",
              "        -2.56260391e-02,  1.60032399e-02,  3.81825417e-02,\n",
              "        -8.70015100e-03, -2.34965198e-02,  1.55745558e-02,\n",
              "         5.66765331e-02,  7.38508403e-02,  1.52101573e-02,\n",
              "        -8.41724779e-03, -6.44073859e-02, -5.55147789e-02,\n",
              "         7.97353163e-02,  3.61876143e-03,  6.64433539e-02,\n",
              "         2.87908819e-02, -2.44696643e-02,  2.12148074e-02,\n",
              "        -1.03562631e-01, -4.12506908e-02,  2.98409145e-02,\n",
              "        -9.24953595e-02,  4.00587684e-03,  6.01527132e-02,\n",
              "        -3.41755338e-02,  3.29850316e-02, -4.83456105e-02,\n",
              "        -3.69678140e-02,  1.21584693e-02, -2.31851321e-02,\n",
              "        -4.88559976e-02,  3.28469574e-02, -4.62379865e-02,\n",
              "         3.91756138e-03, -3.57808322e-02, -1.83101911e-02,\n",
              "        -3.70730162e-02,  3.35949808e-02,  5.02075255e-02,\n",
              "        -5.49601354e-02,  4.69865091e-02, -3.31131332e-02,\n",
              "         1.66335013e-02, -3.02660111e-02,  6.20632321e-02,\n",
              "        -4.43871878e-02,  6.67187944e-02, -6.10227976e-03,\n",
              "         3.40604968e-02, -5.00078723e-02,  2.04586191e-03,\n",
              "         3.39132026e-02, -3.10870837e-02, -1.93446372e-02,\n",
              "         7.54030049e-02, -6.52688146e-02,  5.25344573e-02,\n",
              "        -6.12028465e-02, -3.02657578e-02,  4.56587737e-03,\n",
              "        -8.89162719e-02, -4.83766496e-02, -2.00605318e-02,\n",
              "        -3.86419035e-02,  1.66886132e-02, -1.47099206e-02,\n",
              "         1.01379510e-02, -8.22198391e-02,  2.74562389e-02,\n",
              "        -3.86099308e-03, -1.09152962e-02, -5.79520389e-02,\n",
              "         2.82119941e-02, -1.71919279e-02,  3.00881360e-02,\n",
              "         2.37060878e-02, -2.33154674e-03, -2.97773238e-02,\n",
              "         1.91768520e-02,  5.16294278e-02, -1.44551396e-02,\n",
              "         1.86848231e-02, -2.49356367e-02,  3.22919637e-02,\n",
              "         2.82293633e-02, -2.51183994e-02, -1.08435014e-02,\n",
              "         3.01642790e-02,  5.04571479e-04, -2.27955617e-02,\n",
              "         2.47642398e-02,  6.97232708e-02,  6.99919229e-03,\n",
              "        -7.34954001e-03,  9.45000499e-02, -6.13124855e-02,\n",
              "         2.62528583e-02,  3.58930267e-02,  6.17794786e-03,\n",
              "         3.43658887e-02,  1.17270052e-02,  4.01629843e-02,\n",
              "         1.53442733e-02,  4.48108045e-03,  5.02520762e-02,\n",
              "         1.88765340e-02,  3.31166908e-02, -2.70846896e-02,\n",
              "        -6.57290407e-03,  8.24265853e-02,  1.05237076e-02,\n",
              "         3.99747528e-02,  2.82466039e-03, -1.24388840e-02,\n",
              "        -3.28869629e-03, -7.26752803e-02, -1.81362615e-03,\n",
              "        -2.76129693e-02,  6.45669401e-02,  5.02010882e-02,\n",
              "         6.75971657e-02,  9.59102344e-03, -8.90628695e-02,\n",
              "         1.17860911e-02,  2.72054654e-02, -3.41809331e-03,\n",
              "        -8.05912316e-02, -5.22511154e-02, -3.81535594e-03,\n",
              "        -4.17377055e-02, -9.68294591e-03,  3.78751308e-02,\n",
              "        -5.67596704e-02, -2.05951836e-02, -1.14134252e-02,\n",
              "        -2.83810832e-02,  9.09043923e-02,  3.93438298e-04,\n",
              "        -2.67907092e-03,  1.53438945e-03,  6.49557933e-02,\n",
              "         5.22872917e-02,  1.80281606e-02,  1.84829403e-02,\n",
              "         1.61396265e-02,  5.27072400e-02, -4.12999131e-02,\n",
              "        -4.80413139e-02, -2.36369278e-02, -2.67371312e-02,\n",
              "         3.93584073e-02,  7.55005144e-03, -6.21337928e-02,\n",
              "        -1.67872701e-02,  1.47809321e-03, -5.64959422e-02,\n",
              "         5.52061014e-02, -1.27273258e-02,  1.03164583e-01,\n",
              "        -1.69769581e-02, -2.17627678e-02, -1.17612472e-02,\n",
              "         1.40765943e-02, -1.40489703e-02,  6.19004890e-02,\n",
              "        -3.57006602e-02,  1.31614441e-02, -3.44647840e-02,\n",
              "        -7.06138555e-03,  1.24527086e-02,  8.55674967e-02,\n",
              "         5.42758629e-02, -3.89168896e-02, -7.57954717e-02,\n",
              "        -1.40139628e-02,  1.48370229e-02,  9.68214497e-02,\n",
              "        -1.03704758e-01,  3.29136960e-02, -6.21125400e-02,\n",
              "         1.86114497e-02, -2.82176323e-02, -7.13014323e-03,\n",
              "         4.11863672e-03, -8.93324912e-02, -5.72975874e-02,\n",
              "         4.44727913e-02,  2.29125973e-02,  4.30733897e-03,\n",
              "        -6.96439147e-02, -6.36359528e-02, -2.61848439e-02,\n",
              "        -6.48371428e-02, -9.65941399e-02,  5.09347953e-02,\n",
              "        -8.90865549e-02, -3.94752212e-02, -2.23109871e-02,\n",
              "        -2.93314252e-02,  3.75236683e-02,  4.67261150e-02,\n",
              "         8.62412080e-02, -2.14183982e-02, -5.29951714e-02,\n",
              "         5.89277893e-02,  1.65255815e-02, -1.04241567e-02,\n",
              "        -2.38159653e-02,  1.38605312e-02,  2.62649916e-02,\n",
              "         5.47960252e-02, -4.24158648e-02,  3.17359832e-03,\n",
              "        -3.96554619e-02, -7.35218003e-02,  2.73186038e-03,\n",
              "        -2.72395043e-03, -3.98468450e-02, -4.29545194e-02,\n",
              "         2.14428063e-02,  3.84629183e-02,  3.88852023e-02,\n",
              "         5.13684843e-03, -4.95571457e-02, -3.24903838e-02,\n",
              "         2.83540152e-02, -4.67896983e-02,  1.97179262e-02,\n",
              "        -4.20575552e-02, -7.54898787e-02, -1.03865564e-03,\n",
              "        -6.73990995e-02,  3.91278192e-02,  4.40352261e-02,\n",
              "        -8.06924552e-02, -2.36365572e-02,  5.99047504e-02,\n",
              "         2.12467997e-03,  2.21580155e-02,  4.36153635e-02,\n",
              "         2.49226647e-03,  4.98773716e-03,  7.48324022e-03,\n",
              "        -2.41463818e-02,  4.05476093e-02,  2.91890800e-02,\n",
              "        -1.10162618e-02, -5.65643460e-02, -6.73807710e-02,\n",
              "         4.05558646e-02, -8.50009620e-02, -5.40723242e-02,\n",
              "         7.34481886e-02, -7.35008046e-02,  7.54502695e-03,\n",
              "        -7.00687617e-02,  4.39716354e-02, -2.71130335e-02,\n",
              "        -6.92855120e-02, -2.58242059e-02,  3.92786264e-02,\n",
              "         5.67648746e-02,  1.59089100e-02,  2.35410072e-02,\n",
              "        -5.06520867e-02,  1.17191598e-02, -6.92344606e-02,\n",
              "         1.38218207e-02,  1.09325023e-02,  7.00728670e-02,\n",
              "        -1.26283327e-02,  7.97541440e-02, -3.13802958e-02,\n",
              "        -4.11442071e-02, -3.50070670e-02, -4.26069349e-02,\n",
              "         4.05677184e-02,  7.93018416e-02, -9.75148305e-02,\n",
              "        -1.42815746e-02,  2.42777895e-02, -7.38641918e-02,\n",
              "        -1.56749599e-02, -3.48734409e-02, -5.93835376e-02,\n",
              "        -4.12432663e-02, -4.60710190e-03,  3.71533111e-02,\n",
              "         2.14900654e-02,  5.58095276e-02,  2.14639064e-02,\n",
              "        -6.75328448e-02,  1.01268583e-03,  5.95025048e-02,\n",
              "         1.24675711e-03,  3.76901701e-02,  4.18491662e-02,\n",
              "        -2.79387645e-02, -4.01746593e-02, -8.21425952e-03,\n",
              "        -5.58206476e-02, -1.60544552e-02, -4.75718305e-02,\n",
              "        -5.95801845e-02, -1.01037407e-02, -7.33452216e-02,\n",
              "        -1.84457712e-02,  3.76496203e-02, -8.28180313e-02,\n",
              "         7.54492171e-03, -2.76730042e-02, -3.70695628e-02,\n",
              "        -4.07461822e-02,  7.34213647e-03, -3.86687554e-03,\n",
              "        -1.10504743e-05,  3.76898460e-02,  1.45605877e-02,\n",
              "         2.78659468e-03, -6.57308847e-02, -2.55980827e-02,\n",
              "        -4.81110029e-02,  1.18657313e-02, -2.13191397e-02,\n",
              "         3.31168924e-03,  4.66567390e-02,  4.63187881e-02,\n",
              "        -3.60700265e-02, -7.05618560e-02, -7.14360178e-02,\n",
              "        -9.04085301e-03,  2.11612023e-02, -4.92308028e-02,\n",
              "         3.87155972e-02,  7.73286894e-02,  1.89449079e-02,\n",
              "         3.85826714e-02, -6.83923885e-02, -5.28842509e-02,\n",
              "         8.54228660e-02,  1.28640318e-02,  2.20265985e-02,\n",
              "         2.16055214e-02,  5.56508894e-04,  1.64826140e-02,\n",
              "        -3.31564397e-02,  8.13280344e-02, -2.25724354e-02,\n",
              "        -4.43336181e-02,  7.10498765e-02, -8.87572840e-02,\n",
              "         5.36288209e-02, -6.93188384e-02, -2.98251328e-03,\n",
              "         4.52212617e-02,  4.61279638e-02,  3.65344845e-02,\n",
              "         4.84847240e-02, -2.92588528e-02,  7.36933053e-02,\n",
              "         3.66693214e-02, -6.80679232e-02,  3.96358548e-03,\n",
              "        -9.04875919e-02, -6.32660016e-02, -5.38307913e-02,\n",
              "         6.08242974e-02, -1.84412859e-02,  4.89365570e-02,\n",
              "        -5.12656905e-02, -1.50805674e-02, -5.71214268e-03,\n",
              "        -5.10706715e-02, -6.49115443e-02, -1.13349152e-03,\n",
              "         1.27703268e-02,  1.82183292e-02, -8.28226283e-02,\n",
              "         2.10516318e-03, -3.31831314e-02,  5.95652163e-02,\n",
              "         3.61991338e-02,  5.35384715e-02, -2.25340780e-02,\n",
              "         2.64133271e-02, -3.91572528e-02, -5.87077923e-02,\n",
              "        -1.03312612e-01,  7.44988560e-04,  1.97312646e-02,\n",
              "         3.94936651e-02,  9.22513381e-02, -2.05245204e-02,\n",
              "         2.21597701e-02, -3.13704349e-02, -1.32244118e-02,\n",
              "         4.00840640e-02, -1.50230257e-02,  6.54290393e-02,\n",
              "        -6.08944446e-02,  7.63108721e-04, -3.62863429e-02,\n",
              "         4.91616689e-02, -6.04683533e-02, -1.77060682e-02,\n",
              "         2.45513907e-03, -4.52068150e-02,  3.63887660e-02,\n",
              "        -9.97238010e-02, -2.95221861e-02,  8.41339398e-03,\n",
              "        -8.18829760e-02,  1.82565190e-02,  1.11088185e-02,\n",
              "        -3.46704163e-02, -1.07370205e-02, -4.20162492e-02,\n",
              "        -2.58049518e-02,  3.06181367e-02,  1.86228231e-02,\n",
              "         2.78461562e-03, -3.67317884e-03,  5.00444323e-02,\n",
              "        -2.75492761e-02,  4.84464467e-02,  7.04697743e-02,\n",
              "         9.36839879e-02,  2.49331165e-02, -4.27237339e-02,\n",
              "        -3.15812044e-02, -4.44082767e-02, -3.41433510e-02,\n",
              "         2.81602815e-02, -8.78943317e-03]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d26wfVDOlT_a",
        "outputId": "72330dcd-03aa-4a15-9f39-119d60276084"
      },
      "source": [
        "embed_samples.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-9Y5Jp4lYQq",
        "outputId": "0e7e85b1-147d-49e2-b634-d34ff41f6f0c"
      },
      "source": [
        "len(embed_samples.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhuaigBOmCNQ"
      },
      "source": [
        "Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors, which make no sense to us but hopefully make sense to our machine learning models.\n",
        "\n",
        "Speaking of models, let's build one with the USE as our embedding layer.\n",
        "\n",
        "We can convert the TensorFlow Hub USE module into a Keras layer using the hub.KerasLayer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO-kYYOglaWQ"
      },
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CR7B8zDmoGt",
        "outputId": "bd2d91e6-d867-4cab-ce84-e230ff1e1a17"
      },
      "source": [
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,# take in sentences and then encode them into an embedding\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1,activation=\"sigmoid\")\n",
        "                              ], name = \"model_6_USE\")\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoUU8GfbpJo6"
      },
      "source": [
        "Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the Universal Sentence Encoder paper for more).\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting trainable=True when creating the hub.KerasLayer instance.\n",
        "\n",
        "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our create_tensorboard_callback() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxMqiFXanUei"
      },
      "source": [
        "# input = layers.Input(shape=(1,), dtype=\"string\")\n",
        "# x = embed([input])\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# output = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "# model_6_bis = tf.keras.Model(input,output,name=\"model_6_bis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg8qNQiAoPib",
        "outputId": "a74de935-5619-4d1a-cfbd-d021000b1b9a"
      },
      "source": [
        "model_6_history = model_6.fit(train_data,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_data,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210415-132644\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 30ms/step - loss: 0.5807 - accuracy: 0.7409 - val_loss: 0.4464 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4117 - accuracy: 0.8199 - val_loss: 0.4420 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.4025 - accuracy: 0.8238 - val_loss: 0.4369 - val_accuracy: 0.8071\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3926 - accuracy: 0.8301 - val_loss: 0.4280 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3844 - accuracy: 0.8299 - val_loss: 0.4232 - val_accuracy: 0.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rELmeL--pab_",
        "outputId": "57dac457-1e28-4d71-b7cb-e5b152ad5b7b"
      },
      "source": [
        "model_6_pred_probs = model_6.predict(val_data)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18174729],\n",
              "       [0.77857256],\n",
              "       [0.9916797 ],\n",
              "       [0.21978101],\n",
              "       [0.76260537],\n",
              "       [0.7815589 ],\n",
              "       [0.9872158 ],\n",
              "       [0.98148936],\n",
              "       [0.94806737],\n",
              "       [0.08829779]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsxbRa0zpmlG",
        "outputId": "6dfb7963-2078-48b8-a9aa-ae7487ad71be"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WsXPIbHppMY",
        "outputId": "22f3a576-45d9-44f4-9eee-fec822b25229"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.75853018372703,\n",
              " 'f1': 0.8164548892316194,\n",
              " 'precision': 0.8188543841314186,\n",
              " 'recall': 0.8175853018372703}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaR5BxIDprO6",
        "outputId": "b383cb5d-af3c-4e41-e81f-976773f92996"
      },
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.76, Difference: 2.49\n",
            "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
            "Baseline recall: 0.79, New recall: 0.82, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.82, Difference: 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLejGc09rDLW"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder (retrained)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Cj7rnlpsx4"
      },
      "source": [
        " # We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "\n",
        "sentence_encoder_layer_bis = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=True, # retrain keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE-bis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvBzTSpCrZWZ",
        "outputId": "fc408994-768f-400b-d2ec-0d7850402075"
      },
      "source": [
        "model_6_bis = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer_bis,# take in sentences and then encode them into an embedding\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1,activation=\"sigmoid\")\n",
        "                              ], name = \"model_6_USE_bis\")\n",
        "model_6_bis.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_6_bis.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE_bis\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE-bis (KerasLayer)         (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 256,830,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "S5HfFsuCrmCX",
        "outputId": "62d53d22-bc39-4f64-efcd-fcae9d553124"
      },
      "source": [
        "model_6_history_bis = model_6_bis.fit(train_data,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_data,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"tf_hub_sentence_encoder_bis\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_bis/20210415-131832\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 515s 2s/step - loss: 0.5166 - accuracy: 0.7520 - val_loss: 0.4139 - val_accuracy: 0.8255\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 502s 2s/step - loss: 0.2359 - accuracy: 0.9121 - val_loss: 0.4606 - val_accuracy: 0.8202\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 502s 2s/step - loss: 0.0734 - accuracy: 0.9770 - val_loss: 0.5767 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 503s 2s/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.7650 - val_accuracy: 0.7467\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 503s 2s/step - loss: 0.0233 - accuracy: 0.9887 - val_loss: 0.6693 - val_accuracy: 0.8045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXodWLart5C"
      },
      "source": [
        "model_6_pred_probs_bis = model_6_bis.predict(val_data)\n",
        "model_6_pred_probs_bis[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXXexehur4kI"
      },
      "source": [
        "model_6_results_bis = calculate_results(val_labels, model_6_preds_bis)\n",
        "model_6_results_bis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B8bpfDlr4dw"
      },
      "source": [
        "model_6_preds_bis = tf.squeeze(tf.round(model_6_pred_probs_bis))\n",
        "model_6_preds_bis[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vra6o8D6sEl9"
      },
      "source": [
        "compare_baseline_to_new_results(baseline_results, model_6_results_bis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OawYZFCZsTQ4"
      },
      "source": [
        "One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MEniGwsT4c"
      },
      "source": [
        "#model_7 = tf.keras.models.clone_model(model_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNwus6_dusHm"
      },
      "source": [
        "### Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "NumTJxHXsdDg",
        "outputId": "8060b376-ff35-4b2b-9484-e0c2a4ffb8ef"
      },
      "source": [
        "import pandas as pd\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results,\n",
        "})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.769134</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.765675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.377953</td>\n",
              "      <td>0.764384</td>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.762141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>76.246719</td>\n",
              "      <td>0.762421</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.758530</td>\n",
              "      <td>0.818854</td>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.816455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "lstm                     76.771654   0.769134  0.767717  0.765675\n",
              "gru                      76.377953   0.764384  0.763780  0.762141\n",
              "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
              "conv1d                   76.246719   0.762421  0.762467  0.761322\n",
              "tf_hub_sentence_encoder  81.758530   0.818854  0.817585  0.816455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "EFYajxJTw8HC",
        "outputId": "010f1cc4-aab8-49e0-e818-6a626bf11072"
      },
      "source": [
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.769134</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.765675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.764384</td>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.762141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.762421</td>\n",
              "      <td>0.762467</td>\n",
              "      <td>0.761322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.818854</td>\n",
              "      <td>0.817585</td>\n",
              "      <td>0.816455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "lstm                     0.767717   0.769134  0.767717  0.765675\n",
              "gru                      0.763780   0.764384  0.763780  0.762141\n",
              "bidirectional            0.766404   0.766590  0.766404  0.765121\n",
              "conv1d                   0.762467   0.762421  0.762467  0.761322\n",
              "tf_hub_sentence_encoder  0.817585   0.818854  0.817585  0.816455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "dpVDVOxDxQ2e",
        "outputId": "20a1c96d-c0c6-4a94-ddf6-bed46792fb9b"
      },
      "source": [
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "Nlb2aQtlxZrG",
        "outputId": "2366f2d6-500e-4e1c-db68-6dffb00ec0ef"
      },
      "source": [
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KmctAgHyToC"
      },
      "source": [
        "\n",
        "# View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./model_logs \\\n",
        "  --name \"NLP modelling experiments\" \\\n",
        "  --description \"A series of different NLP modellings experiments with various models\" \\\n",
        "  --one_shot # exits the uploader when upload has finished"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vopSsv2FzpFN"
      },
      "source": [
        "### Combining our models (model ensembling/stacking)\n",
        "\n",
        "Many production systems use an ensemble (multiple different models combined) of models to make a prediction.\n",
        "\n",
        "The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n",
        "\n",
        "The keyword in the sentence above is uncorrelated, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n",
        "\n",
        "Although these models are all trained on the same data, they all have a different way of finding patterns.\n",
        "\n",
        "If we were to use three similarly trained models, such as three LSTM models, the predictions they output will likely be very similar.\n",
        "\n",
        "Think of it as trying to decide where to eat with your friends. If you all have similar tastes, you'll probably all pick the same restaurant. But if you've all got different tastes and still end up picking the same restaurant, the restaurant must be good.\n",
        "\n",
        "Since we're working with a classification problem, there are a few of ways we can combine our models:\n",
        "\n",
        "Averaging - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n",
        "Majority vote (mode) - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict [1, 0, 1] respectively, the majority class is 1, therefore, that would be the predicted label.\n",
        "Model stacking - Take the outputs of each of your chosen models and use them as inputs to another model.\n",
        "\n",
        "> üìñ Resource: The above methods for model stacking/ensembling were adapted from Chapter 6 of the Machine Learning Engineering Book by Andriy Burkov. If you're looking to enter the field of machine learning engineering, not only building models but production-scale machine learning systems, I'd highly recommend reading it in its entirety.\n",
        "\n",
        "We're going to combine our baseline model (model_0), LSTM model (model_2) and our USE model trained on the full training data (model_6) by averaging the combined prediction probabilities of each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40kK_IQfyjr4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}